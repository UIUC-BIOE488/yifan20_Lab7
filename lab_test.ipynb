{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e02337d5-b2fa-4797-84e0-1cbe8436bf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda, float32\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56c44f24-0043-459b-80eb-43ea0d9450aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.082029819488525\n"
     ]
    }
   ],
   "source": [
    "N = np.random.randint(1,5000, 1024**3).astype('float32')\n",
    "M = np.array([0.2, 0.5, 0.3, 0.2, 0.4, 0.1, 0.3, 0.5,0.6,0.7,0.8,0.1,0.2], dtype=np.float32)\n",
    "t0 = time.time()\n",
    "for i in range(1):\n",
    "    P_true = np.convolve(N,np.flip(M), mode='same')\n",
    "t1 = time.time()\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcfb328c-9a83-4ff0-a188-1d3d185fde14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input size\n",
    "Width = len(N)\n",
    "MaskWidth = len(M)\n",
    "P_cuda = np.zeros_like(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fa80183-6609-48b9-980b-3b1c0e891e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the 1D convolution kernel\n",
    "@cuda.jit\n",
    "def cuda_1D_convolution(N, M, P):\n",
    "    i = cuda.grid(1)\n",
    "    if i < len(P):\n",
    "        # Start position for the convolution\n",
    "        start = i - (len(M) // 2)\n",
    "        pValue = 0.0\n",
    "        # Convolution loop\n",
    "        for j in range(len(M)):\n",
    "            if 0 <= start + j < len(N):  # Ensure we are within bounds\n",
    "                pValue += N[start + j] * M[j]\n",
    "        P[i] = pValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "292483a8-4d2c-432a-8095-d8937f08a353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1048576\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "cuda.select_device(0)  # Change to the device ID you want to use\n",
    "\n",
    "# Copy data to GPU\n",
    "d_N = cuda.to_device(N)\n",
    "d_M = cuda.to_device(M)\n",
    "d_P = cuda.to_device(P_cuda)\n",
    "\n",
    "# Configure the kernel\n",
    "threads_per_block = 1024\n",
    "blocks_per_grid = (N.size + (threads_per_block - 1)) // threads_per_block\n",
    "print(blocks_per_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "498815c6-b17b-4135-aab9-ae66ad0956b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3680393695831299\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "for i in range(1):\n",
    "    cuda_1D_convolution[blocks_per_grid, threads_per_block](d_N, d_M, d_P)\n",
    "_=d_P.copy_to_host(P_cuda)\n",
    "t1 = time.time()\n",
    "print(t1-t0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6b76baa-075f-40ac-b30d-860ac96b858a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Your result is correct!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nYour result is {}\".format(\"correct!\" if np.allclose(P_true, P_cuda) else \"incorrect.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f555dcbf-4408-459d-b3ad-7afd1b9e84c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### with shared memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a94471b-d6ec-481e-912a-d2ce90234e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1048576\n"
     ]
    }
   ],
   "source": [
    "P_cuda = np.zeros_like(N)\n",
    "cuda.select_device(1)  # Change to the device ID you want to use\n",
    "\n",
    "# Copy data to GPU\n",
    "d_N = cuda.to_device(N)\n",
    "d_M = cuda.to_device(M)\n",
    "d_P = cuda.to_device(P_cuda)\n",
    "\n",
    "# Configure the kernel\n",
    "threads_per_block = 1024\n",
    "blocks_per_grid = (N.size + (threads_per_block - 1)) // threads_per_block\n",
    "print(blocks_per_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "28704a4c-1640-461a-b923-da86435e62ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = M.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "925a437c-c35b-413f-9fbe-391d0d6531ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the 1D convolution kernel with shared memory optimization\n",
    "@cuda.jit\n",
    "def faster_1D_convolution(N, P):\n",
    "    M = cuda.const.array_like(mask)\n",
    "    radius = len(M) // 2\n",
    "    tile = cuda.shared.array(threads_per_block, dtype=float32)\n",
    "\n",
    "    # Calculate global index and start position for this thread\n",
    "    tid = cuda.threadIdx.x\n",
    "    i = cuda.blockIdx.x * cuda.blockDim.x + tid    \n",
    "\n",
    "    # Load data into shared memory with padding\n",
    "    # Load the main element\n",
    "    if i < len(N):\n",
    "        tile[tid + radius] = N[i]\n",
    "    else:\n",
    "        tile[tid + radius] = 0  # Padding with zero for out-of-bounds\n",
    "\n",
    "    # Load left halo elements for boundary handling\n",
    "    if tid < radius:\n",
    "        if i >= radius:\n",
    "            tile[tid] = N[i - radius]\n",
    "        else:\n",
    "            tile[tid] = 0  # Zero padding for left edge\n",
    "\n",
    "    # Load right halo elements for boundary handling\n",
    "    if tid >= cuda.blockDim.x - radius:\n",
    "        if i + radius < len(N):\n",
    "            tile[tid + 2 * radius] = N[i + radius]\n",
    "        else:\n",
    "            tile[tid + 2 * radius] = 0  # Zero padding for right edge\n",
    "\n",
    "    # Synchronize to make sure all threads have loaded data into shared memory\n",
    "    cuda.syncthreads()\n",
    "\n",
    "    # Perform the convolution\n",
    "    if i < len(P):  # Ensure we don't exceed the output length\n",
    "        pValue = 0.0\n",
    "        for j in range(len(M)):\n",
    "            pValue += tile[tid + j] * M[j]\n",
    "        P[i] = pValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "50060fc8-e81a-42aa-8de0-fd2dd37ab42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37580442428588867\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "for i in range(1):\n",
    "    faster_1D_convolution[blocks_per_grid, threads_per_block](d_N, d_P)\n",
    "_=d_P.copy_to_host(P_cuda)\n",
    "t1 = time.time()\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eac125db-5274-4363-aae1-dd5a3eaa27a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Your result is correct!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nYour result is {}\".format(\"correct!\" if np.allclose(P_true, P_cuda) else \"incorrect.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844a9f0d-cd07-4f78-96aa-fa891232ce9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68eb078f-7d1f-4cfe-a056-b54a435f9ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max threads per block: 1024\n",
      "Max block dimensions: 1024, 1024, 64\n",
      "Max grid dimensions: 2147483647, 65535, 65535\n",
      "Total shared memory per block: 49152 bytes\n"
     ]
    }
   ],
   "source": [
    "from numba import cuda\n",
    "\n",
    "# Select the GPU (if you have more than one, specify the device ID)\n",
    "device = cuda.get_current_device()\n",
    "\n",
    "# Get device properties\n",
    "max_threads_per_block = device.MAX_THREADS_PER_BLOCK\n",
    "max_block_dim_x = device.MAX_BLOCK_DIM_X\n",
    "max_block_dim_y = device.MAX_BLOCK_DIM_Y\n",
    "max_block_dim_z = device.MAX_BLOCK_DIM_Z\n",
    "max_grid_dim_x = device.MAX_GRID_DIM_X\n",
    "max_grid_dim_y = device.MAX_GRID_DIM_Y\n",
    "max_grid_dim_z = device.MAX_GRID_DIM_Z\n",
    "total_shared_memory = device.MAX_SHARED_MEMORY_PER_BLOCK\n",
    "\n",
    "print(f\"Max threads per block: {max_threads_per_block}\")\n",
    "print(f\"Max block dimensions: {max_block_dim_x}, {max_block_dim_y}, {max_block_dim_z}\")\n",
    "print(f\"Max grid dimensions: {max_grid_dim_x}, {max_grid_dim_y}, {max_grid_dim_z}\")\n",
    "print(f\"Total shared memory per block: {total_shared_memory} bytes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf584048-776f-4793-af51-85b113a1aaa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
